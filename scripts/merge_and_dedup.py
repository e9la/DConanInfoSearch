import os
import sys
import zipfile
import re
import json
import logging
import time
from pathlib import Path
from collections import defaultdict
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from utils.config import INTERVIEW_DATA_DIR, PROCESSED_DATA_DIR, LOG_DIR

def extract_time(title):
    match = re.search(r"\d{4}", title)
    return match.group() if match else "æœªçŸ¥"

def extract_participants(content):
    for name in ["é’å±±åˆšæ˜Œ", "å±±å£èƒœå¹³", "é«˜å±±å—", "å €å·ã‚Šã‚‡ã†"]:
        if name in content:
            return name
    return "æœªçŸ¥"

def extract_theme(title, content):
    if "å‰§åœºç‰ˆ" in title:
        return "å‰§åœºç‰ˆè®¿è°ˆ"
    elif "1000è¯" in content:
        return "çºªå¿µè®¿è°ˆ"
    return "å¸¸è§„è®¿è°ˆ"

def is_valid_txt(name):
    return (
        name.endswith(".txt")
        and "__MACOSX" not in name
        and not os.path.basename(name).startswith("._")
    )

def extract_all_texts(data_dir):
    """æå–æ‰€æœ‰ .txt æ–‡ä»¶å’Œ .zip æ–‡ä»¶ä¸­çš„æ–‡æœ¬å†…å®¹ï¼Œæ·»åŠ  title å­—æ®µ"""
    all_entries = []

    for root, _, files in os.walk(data_dir):
        for file in files:
            path = os.path.join(root, file)

            if "__MACOSX" in path or file.startswith("._"):
                continue

            if file.endswith(".txt"):
                try:
                    with open(path, "r", encoding="utf-8") as f:
                        text = f.read().strip()
                    filename = os.path.basename(path).replace(".txt", "")
                    all_entries.append({
                        "text": text,
                        "source": path,
                        "title": filename
                    })
                except Exception as e:
                    logging.warning(f"âŒ æœ¬åœ° txt è§£ç å¤±è´¥: {path} åŸå› : {e}")

            elif file.endswith(".zip"):
                try:
                    with zipfile.ZipFile(path, "r") as zipf:
                        for name in zipf.namelist():
                            if "__MACOSX" in name or os.path.basename(name).startswith("._"):
                                continue
                            if name.endswith(".txt"):
                                try:
                                    with zipf.open(name) as f:
                                        text = f.read().decode("utf-8").strip()
                                    filename = os.path.basename(name).replace(".txt", "")
                                    all_entries.append({
                                        "text": text,
                                        "source": f"{path}:{name}",
                                        "title": filename
                                    })
                                except Exception as e:
                                    logging.warning(f"âŒ zip è§£ç å¤±è´¥: {path} ä¸­çš„ {name}ï¼ŒåŸå› : {e}")
                except Exception as e:
                    logging.error(f"âŒ æ— æ³•æ‰“å¼€ zip æ–‡ä»¶: {path}ï¼ŒåŸå› : {e}")

    return all_entries

def cluster_texts(entries, threshold=0.90):
    texts = [entry["text"] for entry in entries]
    model = SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = model.encode(texts)
    similarity_matrix = cosine_similarity(embeddings)

    clusters = []
    used = set()
    for i in range(len(texts)):
        if i in used:
            continue
        cluster = [i]
        used.add(i)
        for j in range(i + 1, len(texts)):
            if j not in used and similarity_matrix[i][j] > threshold:
                cluster.append(j)
                used.add(j)
        clusters.append(cluster)
    return clusters

def merge_clusters(entries, clusters):
    """æ ¹æ®èšç±»ç»“æœåˆå¹¶å†…å®¹ã€æ¥æºåŠå…ƒä¿¡æ¯"""
    merged = []
    for idx, cluster in enumerate(clusters):
        merged_texts = [entries[i]["text"] for i in cluster]
        sources = [entries[i]["source"] for i in cluster]
        representative_text = merged_texts[0]

        # âœ… ä½¿ç”¨é¦–æ¡çš„ titleï¼Œå¦‚æœæ²¡æœ‰åˆ™ fallback
        raw_title = entries[cluster[0]].get("title", "").strip()
        title = raw_title if raw_title else f"è‡ªåŠ¨ç”Ÿæˆè®¿è°ˆ_{idx+1}"

        metadata = {
            "time": extract_time(title),
            "theme": extract_theme(title, representative_text),
            "participants": extract_participants(representative_text)
        }

        merged.append({
            "id": f"interview_{idx+1}",
            "title": title,
            "content": representative_text,
            "sources": sources,
            "time": metadata["time"],
            "theme": metadata["theme"],
            "participants": metadata["participants"]
        })
    return merged

# åˆå§‹åŒ–æ—¥å¿—ç›®å½•å’Œè®¾ç½®
os.makedirs(LOG_DIR, exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(os.path.join(LOG_DIR, "merge_log.txt"), mode="a", encoding="utf-8")
    ]
)

def main():
    raw_dir = INTERVIEW_DATA_DIR
    output_path = os.path.join(PROCESSED_DATA_DIR, "merged_interviews.json")
    Path(PROCESSED_DATA_DIR).mkdir(parents=True, exist_ok=True)

    start_time = time.time()

    logging.info("ğŸ“‚ æå–æ‰€æœ‰æ–‡æœ¬ä¸­...")
    all_entries = extract_all_texts(raw_dir)
    logging.info(f"âœ… å…±æå–æ–‡æœ¬æ•°é‡: {len(all_entries)}")

    logging.info("ğŸ” è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦å¹¶èšç±»...")
    clusters = cluster_texts(all_entries)
    logging.info(f"âœ… èšç±»å®Œæˆï¼Œç”Ÿæˆè®¿è°ˆæ¡æ•°: {len(clusters)}")

    logging.info("ğŸ§© åˆå¹¶èšç±»å†…å®¹...")
    merged = merge_clusters(all_entries, clusters)

    logging.info(f"ğŸ’¾ ä¿å­˜åˆ° {output_path}")
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(merged, f, ensure_ascii=False, indent=2)

    duration = time.time() - start_time
    logging.info(f"ğŸ‰ å®Œæˆï¼å…±å†™å…¥ {len(merged)} æ¡è®¿è°ˆï¼Œç”¨æ—¶ {duration:.2f} ç§’")

if __name__ == "__main__":
    main()
